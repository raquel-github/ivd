{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guesser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/GuesserModel.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "with open('../data/guesswhat.valid.new.jsonl') as f:\n",
    "    content = f.readlines()\n",
    "    data = [json.loads(x.strip()) for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, test = data[:1500], data[1500:1510]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all object categories\n",
    "obj_cat = set()\n",
    "for d in data:\n",
    "    for obj in d['objects']:\n",
    "        obj_cat.add(obj['category_id'])\n",
    "\n",
    "# create embedding for each category\n",
    "obj_embed_dim = 100\n",
    "obj_embends = nn.Embedding(len(obj_cat), obj_embed_dim)\n",
    "\n",
    "catid2embedid = dict()\n",
    "for i, cat in enumerate(obj_cat):\n",
    "    catid2embedid[cat] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_obj_embeds(catid):\n",
    "    \"\"\" Returns the object embedding for a category \"\"\"\n",
    "    return obj_embends(autograd.Variable(torch.LongTensor([catid2embedid[catid]]))).view(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spatial(bbox, image):\n",
    "    \n",
    "    # get image coordinates\n",
    "    width = image['width']\n",
    "    height = image['height']\n",
    "    image_center_x = width / 2\n",
    "    image_center_y = height / 2\n",
    "\n",
    "    # clalc. norm. coords (between -1 and 1)\n",
    "    x_min = (min(bbox[0], bbox[2]) - image_center_x) / image_center_x\n",
    "    y_min = (min(bbox[1], bbox[3]) - image_center_y) / image_center_y\n",
    "    x_max = (max(bbox[0], bbox[2]) - image_center_x) / image_center_x\n",
    "    y_max = (max(bbox[1], bbox[3]) - image_center_y) / image_center_y\n",
    "    x_center = (x_min + x_max) / 2\n",
    "    y_center = (y_min + y_max) / 2\n",
    "    \n",
    "    w_box = x_max - x_min\n",
    "    h_box = y_max - y_min       \n",
    "    \n",
    "    return autograd.Variable(torch.FloatTensor([x_min, y_min, x_max, y_max, x_center, y_center, w_box, h_box]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Vocablurary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc_question(q):\n",
    "    q = q.lower()\n",
    "    q = '-SOS- ' + q[:q.index('?')] + str(' ? -EOS-')\n",
    "    return q\n",
    "\n",
    "def preproc_answer(a):\n",
    "    a = a.lower()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocablurary created containing 1665 tokens.\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "\n",
    "for d in data:\n",
    "    qas = d['qas']\n",
    "    for qna in qas:\n",
    "        question = preproc_question(qna['question'])\n",
    "        vocab.update(question.split())\n",
    "    \n",
    "        answer = preproc_answer(qna['answer'])\n",
    "        vocab.add(answer)\n",
    "    \n",
    "\n",
    "word2index = dict()\n",
    "index2word = dict()\n",
    "for i, w in enumerate(vocab):\n",
    "    word2index[w] = i\n",
    "    index2word[i] = w\n",
    "\n",
    "print(\"Vocablurary created containing %i tokens.\" %(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM for Question History\n",
    "Takes all questions and answers as input.\n",
    "Last hidden state will be used for object guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Word Emebeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_word_embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from ./glove.6B.100d.pt\n",
      "Loaded 400000 words\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import load_word_vectors\n",
    "\n",
    "wv_dict, wv_arr, wv_size = load_word_vectors('.', 'glove.6B', glove_word_embedding_size)\n",
    "\n",
    "print('Loaded', len(wv_arr), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add SOS and EOS tokens to dict\n",
    "if '-SOS-' not in wv_dict:\n",
    "    wv_dict['-SOS-'] = len(wv_dict)\n",
    "    temp = torch.cat([wv_arr, torch.randn((1,glove_word_embedding_size))])\n",
    "    wv_arr = temp\n",
    "if '-EOS-' not in wv_dict:\n",
    "    wv_dict['-EOS-'] = len(wv_dict)\n",
    "    temp = torch.cat([wv_arr, torch.randn((1,glove_word_embedding_size))])\n",
    "    wv_arr = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wv(w):\n",
    "    \"\"\" returning the word embedding \"\"\"\n",
    "    assert type(w) == str, \"Not given a string.\"\n",
    "    \n",
    "    if w in wv_dict:\n",
    "        vw = wv_arr[wv_dict[w]]\n",
    "        return vw.view(1, glove_word_embedding_size)\n",
    "    else:\n",
    "        print('Word not in Vocab: %s' %(w)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = glove_word_embedding_size\n",
    "hidden_dim = 100\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_in = 8 + obj_embed_dim # 8 comes from the spatial\n",
    "d_h1 = 100\n",
    "d_h2 = 50\n",
    "d_out = hidden_dim # where the output dimension must match the QGen hidden state dimension!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Guesser(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, d_in, d_h1, d_h2, d_out):\n",
    "        super(Guesser, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.object_model = nn.Sequential(\n",
    "            nn.Linear(d_in, d_h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_h1, d_h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_h2, d_out)\n",
    "        )\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, dialogue, objects, image, training=True):\n",
    "        \n",
    "        # Word embedding of dialogue\n",
    "        embeds = autograd.Variable(torch.FloatTensor(len(dialogue.split()), embedding_dim))\n",
    "        for i, w in enumerate(dialogue.split()):\n",
    "            embeds[i] = get_wv(w)\n",
    "        \n",
    "        \n",
    "        # lstm pass\n",
    "        out, self.hidden = self.lstm(embeds.view(len(dialogue.split()), 1, -1), self.hidden)\n",
    "        \n",
    "        \n",
    "        # process objects\n",
    "        proposed_embeddings = autograd.Variable(torch.zeros(len(d['objects']), hidden_dim))\n",
    "        \n",
    "        for i, obj in enumerate(objects):\n",
    "            x = get_spatial(obj['bbox'], image).view(1,-1)\n",
    "            e = get_obj_embeds(catid=obj['category_id'])\n",
    "            y = torch.cat([x, e], dim=1)\n",
    "            proposed_embeddings[i] = self.object_model(y)\n",
    "                \n",
    "        if not training:\n",
    "            print(proposed_embeddings)\n",
    "            print(self.hidden[0].view(hidden_dim,-1))\n",
    "            \n",
    "            \n",
    "        # multiply lstm output with mlp output and apply softmax    \n",
    "        predicted_object = F.log_softmax(torch.mm(proposed_embeddings, self.hidden[0].view(hidden_dim,-1)).t())\n",
    "        \n",
    "        \n",
    "        return predicted_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterations = 1\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Time 66.42 Loss 39.349316\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11321edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Guesser(embedding_dim=embedding_dim, hidden_dim=hidden_dim, vocab_size=vocab_size, \n",
    "                     d_in=d_in, d_h1=d_h1, d_h2=d_h2, d_out=d_out)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "avg_loss = list()\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    _loss = list()\n",
    "    start_time = time()\n",
    "    for d in data:\n",
    "        \n",
    "        # set gradient and hidden layer back to 0\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        \n",
    "        # get objects\n",
    "        object_ids = list()\n",
    "        objects = d['objects']\n",
    "        \n",
    "        for i, obj in enumerate(d['objects']):\n",
    "            object_ids.append(obj['id'])            \n",
    "        \n",
    "        # get image meta\n",
    "        image = d['image']\n",
    "        \n",
    "        # get the lstm input\n",
    "        dialogue = str()\n",
    "        for qna in d['qas']:\n",
    "            question = preproc_question(qna['question'])\n",
    "            answer = preproc_answer(qna['answer'])\n",
    "            dialogue += question + ' ' + answer + ' '\n",
    "          \n",
    "        \n",
    "        # check if embeddings for all words in the dialogue exist\n",
    "        wv_for_dialogue = True\n",
    "        for w in dialogue.split():\n",
    "            if w not in wv_dict:\n",
    "                wv_for_dialogue = False\n",
    "                break\n",
    "                \n",
    "        if wv_for_dialogue == False:\n",
    "            continue\n",
    "        \n",
    "        # make prediction\n",
    "        predicted_object = model(dialogue, objects, image)\n",
    "        \n",
    "        \n",
    "        # get target\n",
    "        target_id = d['object_id']\n",
    "        target = autograd.Variable(torch.LongTensor([object_ids.index(target_id)]))\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_function(predicted_object, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()           \n",
    "        \n",
    "        \n",
    "        # bookkeeping\n",
    "        _loss.append(loss.data.numpy())\n",
    "        \n",
    "    avg_loss.append(numpy.mean(_loss))\n",
    "    print('Epoch %i Time %.2f Loss %f' %(epoch, time()-start_time, avg_loss[-1]))\n",
    "\n",
    "plt.plot(avg_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = test[2]\n",
    "object_ids = list()\n",
    "objects = d['objects']\n",
    "\n",
    "for i, obj in enumerate(d['objects']):\n",
    "    object_ids.append(obj['id'])            \n",
    "\n",
    "\n",
    "# get the lstm input\n",
    "dialogue = str()\n",
    "for qna in d['qas']:\n",
    "    question = preproc_question(qna['question'])\n",
    "    answer = preproc_answer(qna['answer'])\n",
    "    dialogue += question + ' ' + answer + ' '\n",
    "    \n",
    "target_id = d['object_id']\n",
    "target = autograd.Variable(torch.LongTensor([object_ids.index(target_id)]))\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      "-5.2902e-02 -1.0598e-01 -1.1161e-02  5.2882e-02 -4.0427e-02  6.5104e-02\n",
      "-5.2902e-02 -1.0598e-01 -1.1161e-02  5.2882e-02 -4.0427e-02  6.5104e-02\n",
      "-5.2902e-02 -1.0598e-01 -1.1161e-02  5.2882e-02 -4.0427e-02  6.5104e-02\n",
      "-5.2902e-02 -1.0598e-01 -1.1161e-02  5.2882e-02 -4.0427e-02  6.5104e-02\n",
      "-5.2902e-02 -1.0598e-01 -1.1161e-02  5.2882e-02 -4.0427e-02  6.5104e-02\n",
      "-5.2902e-02 -1.0598e-01 -1.1161e-02  5.2882e-02 -4.0427e-02  6.5104e-02\n",
      "-5.2902e-02 -1.0598e-01 -1.1161e-02  5.2882e-02 -4.0427e-02  6.5104e-02\n",
      "\n",
      "Columns 6 to 11 \n",
      "-1.8639e-02  9.5920e-02  1.1119e-02 -8.4981e-02  4.3430e-02  9.4486e-03\n",
      "-1.8639e-02  9.5920e-02  1.1119e-02 -8.4981e-02  4.3430e-02  9.4486e-03\n",
      "-1.8639e-02  9.5920e-02  1.1119e-02 -8.4981e-02  4.3430e-02  9.4486e-03\n",
      "-1.8639e-02  9.5920e-02  1.1119e-02 -8.4981e-02  4.3430e-02  9.4486e-03\n",
      "-1.8639e-02  9.5920e-02  1.1119e-02 -8.4981e-02  4.3430e-02  9.4486e-03\n",
      "-1.8639e-02  9.5920e-02  1.1119e-02 -8.4981e-02  4.3430e-02  9.4486e-03\n",
      "-1.8639e-02  9.5920e-02  1.1119e-02 -8.4981e-02  4.3430e-02  9.4486e-03\n",
      "\n",
      "Columns 12 to 17 \n",
      " 1.6127e+02  4.1187e-02 -1.1146e-01  1.5221e+02 -1.7304e+02  1.5722e+02\n",
      " 1.6127e+02  4.1187e-02 -1.1146e-01  1.5221e+02 -1.7304e+02  1.5722e+02\n",
      " 1.6127e+02  4.1187e-02 -1.1146e-01  1.5221e+02 -1.7304e+02  1.5722e+02\n",
      " 1.6127e+02  4.1187e-02 -1.1146e-01  1.5221e+02 -1.7304e+02  1.5722e+02\n",
      " 1.6127e+02  4.1187e-02 -1.1146e-01  1.5221e+02 -1.7304e+02  1.5722e+02\n",
      " 1.6127e+02  4.1187e-02 -1.1146e-01  1.5221e+02 -1.7304e+02  1.5722e+02\n",
      " 1.6127e+02  4.1187e-02 -1.1146e-01  1.5221e+02 -1.7304e+02  1.5722e+02\n",
      "\n",
      "Columns 18 to 23 \n",
      "-1.9582e-02 -1.9698e-02 -1.2115e-01  1.2485e-01 -1.4510e+02 -8.7663e-02\n",
      "-1.9582e-02 -1.9698e-02 -1.2115e-01  1.2485e-01 -1.4510e+02 -8.7663e-02\n",
      "-1.9582e-02 -1.9698e-02 -1.2115e-01  1.2485e-01 -1.4510e+02 -8.7663e-02\n",
      "-1.9582e-02 -1.9698e-02 -1.2115e-01  1.2485e-01 -1.4510e+02 -8.7663e-02\n",
      "-1.9582e-02 -1.9698e-02 -1.2115e-01  1.2485e-01 -1.4510e+02 -8.7663e-02\n",
      "-1.9582e-02 -1.9698e-02 -1.2115e-01  1.2485e-01 -1.4510e+02 -8.7663e-02\n",
      "-1.9582e-02 -1.9698e-02 -1.2115e-01  1.2485e-01 -1.4510e+02 -8.7663e-02\n",
      "\n",
      "Columns 24 to 29 \n",
      " 6.8848e-02 -8.9962e-02  3.9897e-02 -6.5400e-02  6.4194e-03 -1.6176e+02\n",
      " 6.8848e-02 -8.9962e-02  3.9897e-02 -6.5400e-02  6.4194e-03 -1.6176e+02\n",
      " 6.8848e-02 -8.9962e-02  3.9897e-02 -6.5400e-02  6.4194e-03 -1.6176e+02\n",
      " 6.8848e-02 -8.9962e-02  3.9897e-02 -6.5400e-02  6.4194e-03 -1.6176e+02\n",
      " 6.8848e-02 -8.9962e-02  3.9897e-02 -6.5400e-02  6.4194e-03 -1.6176e+02\n",
      " 6.8848e-02 -8.9962e-02  3.9897e-02 -6.5400e-02  6.4194e-03 -1.6176e+02\n",
      " 6.8848e-02 -8.9962e-02  3.9897e-02 -6.5400e-02  6.4194e-03 -1.6176e+02\n",
      "\n",
      "Columns 30 to 35 \n",
      " 1.4394e-01 -6.0377e-02 -1.1576e-01 -1.1184e-01 -3.3700e-02 -1.0169e-01\n",
      " 1.4394e-01 -6.0377e-02 -1.1576e-01 -1.1184e-01 -3.3700e-02 -1.0169e-01\n",
      " 1.4394e-01 -6.0377e-02 -1.1576e-01 -1.1184e-01 -3.3700e-02 -1.0169e-01\n",
      " 1.4394e-01 -6.0377e-02 -1.1576e-01 -1.1184e-01 -3.3700e-02 -1.0169e-01\n",
      " 1.4394e-01 -6.0377e-02 -1.1576e-01 -1.1184e-01 -3.3700e-02 -1.0169e-01\n",
      " 1.4394e-01 -6.0377e-02 -1.1576e-01 -1.1184e-01 -3.3700e-02 -1.0169e-01\n",
      " 1.4394e-01 -6.0377e-02 -1.1576e-01 -1.1184e-01 -3.3700e-02 -1.0169e-01\n",
      "\n",
      "Columns 36 to 41 \n",
      "-1.4258e+02  1.8232e+02 -7.8519e-02  1.6008e+02  1.1816e-02  6.8238e-02\n",
      "-1.4258e+02  1.8232e+02 -7.8519e-02  1.6008e+02  1.1816e-02  6.8238e-02\n",
      "-1.4258e+02  1.8232e+02 -7.8519e-02  1.6008e+02  1.1816e-02  6.8238e-02\n",
      "-1.4258e+02  1.8232e+02 -7.8519e-02  1.6008e+02  1.1816e-02  6.8238e-02\n",
      "-1.4258e+02  1.8232e+02 -7.8519e-02  1.6008e+02  1.1816e-02  6.8238e-02\n",
      "-1.4258e+02  1.8232e+02 -7.8519e-02  1.6008e+02  1.1816e-02  6.8238e-02\n",
      "-1.4258e+02  1.8232e+02 -7.8519e-02  1.6008e+02  1.1816e-02  6.8238e-02\n",
      "\n",
      "Columns 42 to 47 \n",
      " 2.0434e-02  4.8253e+01  1.1464e-01 -1.1243e-01 -9.0799e-02  9.2597e-02\n",
      " 2.0434e-02  4.8253e+01  1.1464e-01 -1.1243e-01 -9.0799e-02  9.2597e-02\n",
      " 2.0434e-02  4.8253e+01  1.1464e-01 -1.1243e-01 -9.0799e-02  9.2597e-02\n",
      " 2.0434e-02  4.8253e+01  1.1464e-01 -1.1243e-01 -9.0799e-02  9.2597e-02\n",
      " 2.0434e-02  4.8253e+01  1.1464e-01 -1.1243e-01 -9.0799e-02  9.2597e-02\n",
      " 2.0434e-02  4.8253e+01  1.1464e-01 -1.1243e-01 -9.0799e-02  9.2597e-02\n",
      " 2.0434e-02  4.8253e+01  1.1464e-01 -1.1243e-01 -9.0799e-02  9.2597e-02\n",
      "\n",
      "Columns 48 to 53 \n",
      "-8.7124e-02 -2.1997e-02  9.1904e-02 -4.1918e-02  4.2320e-02 -2.2422e-02\n",
      "-8.7124e-02 -2.1997e-02  9.1904e-02 -4.1918e-02  4.2320e-02 -2.2422e-02\n",
      "-8.7124e-02 -2.1997e-02  9.1904e-02 -4.1918e-02  4.2320e-02 -2.2422e-02\n",
      "-8.7124e-02 -2.1997e-02  9.1904e-02 -4.1918e-02  4.2320e-02 -2.2422e-02\n",
      "-8.7124e-02 -2.1997e-02  9.1904e-02 -4.1918e-02  4.2320e-02 -2.2422e-02\n",
      "-8.7124e-02 -2.1997e-02  9.1904e-02 -4.1918e-02  4.2320e-02 -2.2422e-02\n",
      "-8.7124e-02 -2.1997e-02  9.1904e-02 -4.1918e-02  4.2320e-02 -2.2422e-02\n",
      "\n",
      "Columns 54 to 59 \n",
      " 2.0780e-01  6.5402e-02 -1.1711e-01  1.2101e-02 -9.8260e-02 -3.9585e-02\n",
      " 2.0780e-01  6.5402e-02 -1.1711e-01  1.2101e-02 -9.8260e-02 -3.9585e-02\n",
      " 2.0780e-01  6.5402e-02 -1.1711e-01  1.2101e-02 -9.8260e-02 -3.9585e-02\n",
      " 2.0780e-01  6.5402e-02 -1.1711e-01  1.2101e-02 -9.8260e-02 -3.9585e-02\n",
      " 2.0780e-01  6.5402e-02 -1.1711e-01  1.2101e-02 -9.8260e-02 -3.9585e-02\n",
      " 2.0780e-01  6.5402e-02 -1.1711e-01  1.2101e-02 -9.8260e-02 -3.9585e-02\n",
      " 2.0780e-01  6.5402e-02 -1.1711e-01  1.2101e-02 -9.8260e-02 -3.9585e-02\n",
      "\n",
      "Columns 60 to 65 \n",
      " 1.6516e+02 -1.3269e-01 -1.4382e-01  7.9622e-02 -1.0245e-01 -1.0031e-01\n",
      " 1.6516e+02 -1.3269e-01 -1.4382e-01  7.9622e-02 -1.0245e-01 -1.0031e-01\n",
      " 1.6516e+02 -1.3269e-01 -1.4382e-01  7.9622e-02 -1.0245e-01 -1.0031e-01\n",
      " 1.6516e+02 -1.3269e-01 -1.4382e-01  7.9622e-02 -1.0245e-01 -1.0031e-01\n",
      " 1.6516e+02 -1.3269e-01 -1.4382e-01  7.9622e-02 -1.0245e-01 -1.0031e-01\n",
      " 1.6516e+02 -1.3269e-01 -1.4382e-01  7.9622e-02 -1.0245e-01 -1.0031e-01\n",
      " 1.6516e+02 -1.3269e-01 -1.4382e-01  7.9622e-02 -1.0245e-01 -1.0031e-01\n",
      "\n",
      "Columns 66 to 71 \n",
      "-1.3145e-01 -1.1271e-01  2.6611e-04 -1.0838e+02 -6.7054e-02 -8.1540e+01\n",
      "-1.3145e-01 -1.1271e-01  2.6611e-04 -1.0838e+02 -6.7054e-02 -8.1540e+01\n",
      "-1.3145e-01 -1.1271e-01  2.6611e-04 -1.0838e+02 -6.7054e-02 -8.1540e+01\n",
      "-1.3145e-01 -1.1271e-01  2.6611e-04 -1.0838e+02 -6.7054e-02 -8.1540e+01\n",
      "-1.3145e-01 -1.1271e-01  2.6611e-04 -1.0838e+02 -6.7054e-02 -8.1540e+01\n",
      "-1.3145e-01 -1.1271e-01  2.6611e-04 -1.0838e+02 -6.7054e-02 -8.1540e+01\n",
      "-1.3145e-01 -1.1271e-01  2.6611e-04 -1.0838e+02 -6.7054e-02 -8.1540e+01\n",
      "\n",
      "Columns 72 to 77 \n",
      "-1.6955e+02  5.6332e-02  6.0062e-02  4.8701e-02 -8.7564e-02 -6.4501e-02\n",
      "-1.6955e+02  5.6332e-02  6.0062e-02  4.8701e-02 -8.7564e-02 -6.4501e-02\n",
      "-1.6955e+02  5.6332e-02  6.0062e-02  4.8701e-02 -8.7564e-02 -6.4501e-02\n",
      "-1.6955e+02  5.6332e-02  6.0062e-02  4.8701e-02 -8.7564e-02 -6.4501e-02\n",
      "-1.6955e+02  5.6332e-02  6.0062e-02  4.8701e-02 -8.7564e-02 -6.4501e-02\n",
      "-1.6955e+02  5.6332e-02  6.0062e-02  4.8701e-02 -8.7564e-02 -6.4501e-02\n",
      "-1.6955e+02  5.6332e-02  6.0062e-02  4.8701e-02 -8.7564e-02 -6.4501e-02\n",
      "\n",
      "Columns 78 to 83 \n",
      "-1.2942e-02 -8.8765e-02  1.4514e+02 -1.0673e-01 -1.5130e+02 -1.6206e-01\n",
      "-1.2942e-02 -8.8765e-02  1.4514e+02 -1.0673e-01 -1.5130e+02 -1.6206e-01\n",
      "-1.2942e-02 -8.8765e-02  1.4514e+02 -1.0673e-01 -1.5130e+02 -1.6206e-01\n",
      "-1.2942e-02 -8.8765e-02  1.4514e+02 -1.0673e-01 -1.5130e+02 -1.6206e-01\n",
      "-1.2942e-02 -8.8765e-02  1.4514e+02 -1.0673e-01 -1.5130e+02 -1.6206e-01\n",
      "-1.2942e-02 -8.8765e-02  1.4514e+02 -1.0673e-01 -1.5130e+02 -1.6206e-01\n",
      "-1.2942e-02 -8.8765e-02  1.4514e+02 -1.0673e-01 -1.5130e+02 -1.6206e-01\n",
      "\n",
      "Columns 84 to 89 \n",
      "-1.0969e-01 -1.3209e+00  1.3279e+02 -2.7075e-02 -2.1641e-02 -1.3002e+02\n",
      "-1.0969e-01 -1.3209e+00  1.3279e+02 -2.7075e-02 -2.1641e-02 -1.3002e+02\n",
      "-1.0969e-01 -1.3209e+00  1.3279e+02 -2.7075e-02 -2.1641e-02 -1.3002e+02\n",
      "-1.0969e-01 -1.3209e+00  1.3279e+02 -2.7075e-02 -2.1641e-02 -1.3002e+02\n",
      "-1.0969e-01 -1.3209e+00  1.3279e+02 -2.7075e-02 -2.1641e-02 -1.3002e+02\n",
      "-1.0969e-01 -1.3209e+00  1.3279e+02 -2.7075e-02 -2.1641e-02 -1.3002e+02\n",
      "-1.0969e-01 -1.3209e+00  1.3279e+02 -2.7075e-02 -2.1641e-02 -1.3002e+02\n",
      "\n",
      "Columns 90 to 95 \n",
      " 5.7731e-02  1.0808e-01 -1.3907e-01  6.3352e-02 -1.5288e+02 -5.6669e-02\n",
      " 5.7731e-02  1.0808e-01 -1.3907e-01  6.3352e-02 -1.5288e+02 -5.6669e-02\n",
      " 5.7731e-02  1.0808e-01 -1.3907e-01  6.3352e-02 -1.5288e+02 -5.6669e-02\n",
      " 5.7731e-02  1.0808e-01 -1.3907e-01  6.3352e-02 -1.5288e+02 -5.6669e-02\n",
      " 5.7731e-02  1.0808e-01 -1.3907e-01  6.3352e-02 -1.5288e+02 -5.6669e-02\n",
      " 5.7731e-02  1.0808e-01 -1.3907e-01  6.3352e-02 -1.5288e+02 -5.6669e-02\n",
      " 5.7731e-02  1.0808e-01 -1.3907e-01  6.3352e-02 -1.5288e+02 -5.6669e-02\n",
      "\n",
      "Columns 96 to 99 \n",
      " 1.3172e+02  1.3011e+02 -3.3424e-02 -1.3420e-01\n",
      " 1.3172e+02  1.3011e+02 -3.3424e-02 -1.3420e-01\n",
      " 1.3172e+02  1.3011e+02 -3.3424e-02 -1.3420e-01\n",
      " 1.3172e+02  1.3011e+02 -3.3424e-02 -1.3420e-01\n",
      " 1.3172e+02  1.3011e+02 -3.3424e-02 -1.3420e-01\n",
      " 1.3172e+02  1.3011e+02 -3.3424e-02 -1.3420e-01\n",
      " 1.3172e+02  1.3011e+02 -3.3424e-02 -1.3420e-01\n",
      "[torch.FloatTensor of size 7x100]\n",
      "\n",
      "Variable containing:\n",
      " 7.2162e-14\n",
      " 1.5932e-18\n",
      "-1.7552e-21\n",
      "-3.6379e-07\n",
      "-3.1246e-12\n",
      " 4.7077e-28\n",
      " 1.5437e-17\n",
      " 2.6598e-13\n",
      " 9.6796e-27\n",
      "-1.9453e-18\n",
      "-4.4008e-11\n",
      "-2.0391e-16\n",
      " 7.6159e-01\n",
      " 1.5381e-15\n",
      "-4.2639e-15\n",
      " 1.0000e+00\n",
      "-1.0000e+00\n",
      " 7.6159e-01\n",
      " 9.2577e-28\n",
      "-9.0285e-23\n",
      "-1.1623e-12\n",
      "-5.5558e-25\n",
      "-7.6159e-01\n",
      " 8.7052e-14\n",
      "-1.8767e-14\n",
      " 1.8984e-15\n",
      " 3.0228e-08\n",
      "-3.8679e-13\n",
      " 1.2089e-09\n",
      "-7.6159e-01\n",
      " 2.5525e-13\n",
      " 2.3151e-09\n",
      " 3.2016e-15\n",
      " 8.4447e-12\n",
      " 7.8782e-08\n",
      "-3.2811e-08\n",
      "-7.4213e-01\n",
      " 7.6159e-01\n",
      " 9.2698e-13\n",
      " 7.6158e-01\n",
      "-1.3805e-16\n",
      "-5.9252e-15\n",
      " 1.5511e-14\n",
      " 5.1853e-05\n",
      " 1.7489e-14\n",
      " 1.4420e-14\n",
      " 7.1932e-17\n",
      " 5.7900e-11\n",
      "-7.5222e-26\n",
      "-2.1995e-15\n",
      "-9.7280e-12\n",
      "-7.0380e-20\n",
      "-5.6937e-11\n",
      " 3.9395e-24\n",
      " 2.0908e-09\n",
      " 2.7106e-10\n",
      " 9.2561e-16\n",
      " 3.2791e-14\n",
      " 2.7311e-16\n",
      " 6.0299e-17\n",
      " 1.0000e+00\n",
      "-1.9844e-13\n",
      " 3.5357e-12\n",
      " 3.6052e-17\n",
      "-3.3385e-14\n",
      "-1.7971e-14\n",
      " 8.0049e-25\n",
      "-5.3220e-08\n",
      " 2.6516e-14\n",
      "-7.6136e-01\n",
      " 4.0220e-21\n",
      "-7.6159e-01\n",
      "-7.6159e-01\n",
      " 7.0511e-17\n",
      " 2.8093e-11\n",
      "-1.0122e-15\n",
      "-3.1706e-13\n",
      " 3.1754e-16\n",
      "-1.4234e-15\n",
      "-7.5134e-23\n",
      " 7.6159e-01\n",
      " 1.1984e-09\n",
      "-7.6159e-01\n",
      " 1.8142e-10\n",
      " 1.3691e-14\n",
      " 6.8399e-12\n",
      " 7.6159e-01\n",
      " 2.2905e-17\n",
      "-7.3408e-08\n",
      "-7.6159e-01\n",
      "-3.2769e-21\n",
      " 8.0139e-16\n",
      "-8.0640e-18\n",
      " 3.5449e-16\n",
      "-7.6094e-01\n",
      "-3.2006e-16\n",
      " 7.6159e-01\n",
      " 7.6159e-01\n",
      " 5.9947e-11\n",
      " 1.0205e-14\n",
      "[torch.FloatTensor of size 100x1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.9459 -1.9459 -1.9459 -1.9459 -1.9459 -1.9459 -1.9459\n",
       "[torch.FloatTensor of size 1x7]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(dialogue, objects, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2  3  4\n",
      " 5  6  7  8\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "\n",
      "    1     2     3     4     5     6     7     8\n",
      "[torch.FloatTensor of size 1x8]\n",
      "\n",
      "\n",
      " 1  2  3  4\n",
      " 5  6  7  8\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.Tensor([[1,2,3,4]])\n",
    "y = torch.Tensor([[5,6,7,8]])\n",
    "z = torch.cat([x,y], dim=0)\n",
    "print(z)\n",
    "z = torch.cat([x,y], dim=1)\n",
    "print(z)\n",
    "x = torch.cat([x,y],dim=0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
