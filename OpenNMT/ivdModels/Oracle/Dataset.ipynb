{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_file = '../../../../ivd_data/Oracle/oracle.val.json'\n",
    "train_file = '../../../../ivd_data/Oracle/oracle.train.json'\n",
    "test_file = '../../../../ivd_data/Oracle/oracle.test.json'\n",
    "small_file = '../../../seq2seq/Preprocessing/Data/oracle.small.test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'No',\n",
       " 'crop_features': '2488.jpg',\n",
       " 'game_id': 2488,\n",
       " 'img_features': 'COCO_train2014_000000175527.jpg',\n",
       " 'obj_cat': 9,\n",
       " 'question': 'is it in the sky?',\n",
       " 'spatial': [0.6765, 0.7561, 0.9207, 0.9261, 0.7986, 0.8411, 0.1221, 0.085]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(test_file) as f:\n",
    "    data = json.load(f)['questions']\n",
    "print(len(data))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg:  4.87682264757\n",
      "Median:  4.0\n",
      "80 Perecentile:  6.0\n",
      "90 Perecentile:  8.0\n",
      "99 Perecentile:  13.0\n"
     ]
    }
   ],
   "source": [
    "# get statistics about questions\n",
    "question_lengths = list()\n",
    "for datapoint in data:\n",
    "    q = datapoint['question']\n",
    "    question_lengths.append(len(q.split()))\n",
    "        \n",
    "print(\"Avg: \", np.mean(question_lengths))\n",
    "print(\"Median: \", np.median(question_lengths))\n",
    "print(\"80 Perecentile: \", np.percentile(question_lengths, 80))\n",
    "print(\"90 Perecentile: \", np.percentile(question_lengths, 90))\n",
    "print(\"99 Perecentile: \", np.percentile(question_lengths, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]\n"
     ]
    }
   ],
   "source": [
    "obj_cat = []\n",
    "for datum in data:\n",
    "    obj_cat.append(datum['obj_cat'])\n",
    "    \n",
    "obj_cat = list(set(obj_cat))\n",
    "print(len(obj_cat))\n",
    "print(obj_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121938\n",
      "38362\n",
      "23969\n",
      "['continuing', 'to', 'move', 'right', 'is', 'it', 'the', 'person', 'behind', 'and', 'to', 'our', 'right', 'of', 'the', 'first', 'row', 'man', 'in', 'the', 'white', 'shirt', 'and', 'a', 'black', 'hat', 'with', 'a', 'stripe', 'across', 'the', 'front', '?']\n",
      "33\n",
      "['?']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "questions = [re.findall(r'\\w+', datum['question'].lower())+['?'] for datum in data]\n",
    "# questions = [re.findall(\"[a-zA-Z]+\", datum['question'].lower()) for datum in data]\n",
    "# questions = [datum['question'].lower().split() for datum in data]\n",
    "# for q in questions:\n",
    "#     for idx in range(len(q)):\n",
    "#         if q[idx][-1] == '?':\n",
    "#             q[idx] = q[idx][:-1]\n",
    "#         if idx == len(q)-1:\n",
    "#             q += '?'\n",
    "print(len(questions))\n",
    "max_length = max(questions,key=len)\n",
    "min_length = min(questions,key=len)\n",
    "print(questions.index(max_length))\n",
    "print(questions.index(min_length))\n",
    "print(max_length)\n",
    "print(len(max_length))\n",
    "print(min_length)\n",
    "print(len(min_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5069\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(int)\n",
    "vocab['-PAD-'] = 6\n",
    "vocab['-UNK-'] = 6\n",
    "\n",
    "for line in questions:\n",
    "    for word in line:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "# vocab = list(set(vocab))\n",
    "print(len(vocab))\n",
    "vocab_temp = dict(vocab)\n",
    "for w in vocab_temp:\n",
    "    if vocab[w] < 3:\n",
    "        vocab.pop(w)\n",
    "del vocab_temp\n",
    "print(len(vocab))\n",
    "# for w in sorted(vocab, key=vocab.get, reverse=True):\n",
    "#       print(w, vocab[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2ind = {}\n",
    "ind2word = {}\n",
    "\n",
    "for idx, w in enumerate(sorted(vocab, key=vocab.get, reverse=True)):\n",
    "    ind2word[idx] = w\n",
    "    word2ind[w] = idx\n",
    "\n",
    "# print(ind2word)\n",
    "# print(word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# json_data = {'word2ind':word2ind, 'ind2word':ind2word}\n",
    "\n",
    "# with open('vocabOracle.json','w') as vc:\n",
    "#     json.dump(json_data, vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'No',\n",
       " 'crop_features': '2426.jpg',\n",
       " 'game_id': 2426,\n",
       " 'img_features': 'COCO_train2014_000000460809.jpg',\n",
       " 'obj_cat': 44,\n",
       " 'question': 'does the container have a picture?',\n",
       " 'spatial': [-0.3059,\n",
       "  -0.9893,\n",
       "  -0.2675,\n",
       "  -0.9128,\n",
       "  -0.2867,\n",
       "  -0.9511,\n",
       "  0.0192,\n",
       "  0.0382]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0393373   0.49363673 -0.23234019 ..., -0.1444326   0.16763082\n",
      "  0.14814836]\n",
      "46794\n"
     ]
    }
   ],
   "source": [
    "filename = '../../../../ivd_data/img_features/image_features.h5'\n",
    "\n",
    "h5data = h5py.File(filename, 'r')\n",
    "train_data = h5data['train_img_features']\n",
    "del h5data\n",
    "print(train_data[0])\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OracleDataset(Dataset):\n",
    "    def __init__(self, split, json_data_file, img_features_file, img2id_file, crop_features_file, crop2id_file, vocab_json_file):\n",
    "        \"\"\"\n",
    "        split: ['train', 'val', 'test']\n",
    "        \"\"\"\n",
    "        with open(json_data_file) as file:\n",
    "            self.questions = json.load(file)['questions']\n",
    "        with open(img2id_file) as file:\n",
    "            self.img2id = json.load(file)[split+'2id']\n",
    "        with open(crop2id_file) as file:\n",
    "            self.crop2id = json.load(file)[split+'crops2id']\n",
    "        \n",
    "        img_h5data = h5py.File(img_features_file, 'r')\n",
    "        self.img_features = img_h5data[split+'_img_features']\n",
    "        del img_h5data\n",
    "        crop_h5data = h5py.File(crop_features_file, 'r')\n",
    "        self.crop_features = crop_h5data[split+'_crop_features']\n",
    "        del crop_h5data\n",
    "        \n",
    "        self.ans2id = {'no':0, 'yes':1, 'n/a':2}\n",
    "        with open(vocab_json_file) as file:\n",
    "            self.word2ind = json.load(file)['word2ind']\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        crop_features = self.crop_features[self.crop2id[self.questions[idx]['crop_features']]]\n",
    "        img_features = self.img_features[self.img2id[self.questions[idx]['img_features']]]\n",
    "        spaital = torch.FloatTensor(self.questions[idx]['spatial'])\n",
    "        obj_cat = self.questions[idx]['obj_cat']\n",
    "        \n",
    "        raw_question = self.questions[idx]['question']\n",
    "        question = (np.ones(45,'uint8')*self.word2ind['-PAD-']).tolist()\n",
    "        for wid, word in enumerate(re.findall(r'\\w+', raw_question.lower())+['?']):\n",
    "            if word in self.word2ind:\n",
    "                question[wid] = self.word2ind[word]\n",
    "            else:\n",
    "                question[wid] = self.word2ind['-UNK-']\n",
    "            \n",
    "        question = torch.LongTensor(question)\n",
    "        answer = self.ans2id[self.questions[idx]['answer'].lower()]\n",
    "        \n",
    "        sample = {'question':question, 'answer': answer, 'crop_features':crop_features, 'img_features':img_features,\\\n",
    "                  'spaital':spaital, 'obj_cat':obj_cat}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 'val'\n",
    "json_data_file = '../../../../ivd_data/Oracle/oracle.val.json'\n",
    "vocab_json_file = 'vocabOracle.json'\n",
    "img_features_file = '../../../../ivd_data/img_features/image_features.h5'\n",
    "img2id_file = '../../../../ivd_data/img_features/img_features2id.json'\n",
    "crop_features_file = '../../../../ivd_data/img_features/crop_features.h5'\n",
    "crop2id_file = '../../../../ivd_data/img_features/crop_features2id.json'\n",
    "\n",
    "od = OracleDataset(split, json_data_file, img_features_file, img2id_file, crop_features_file, crop2id_file, vocab_json_file)\n",
    "od[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4820237159729004\n",
      "0.0004048347473144531\n",
      "0.0011034011840820312\n",
      "0.10975170135498047\n",
      "0.005167484283447266\n",
      "0.1707758903503418\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(od, batch_size=128, shuffle=True, num_workers=4, pin_memory=False)\n",
    "count = 0\n",
    "start = time()\n",
    "for sample in dataloader:\n",
    "    print(time()-start)\n",
    "    if count == 5:\n",
    "        print(sample['crop_features'].size()[0])\n",
    "        break\n",
    "    count += 1\n",
    "    start = time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.3122749328613281\n",
    "0.009618043899536133\n",
    "0.01502084732055664\n",
    "0.0002598762512207031\n",
    "0.07806873321533203\n",
    "0.011798858642578125"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
